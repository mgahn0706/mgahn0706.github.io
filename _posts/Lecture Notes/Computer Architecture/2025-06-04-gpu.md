---  
tags:  
  - GPU  
share: "true"  
github_title: 2025-06-04-gpu  
title: 23. GPU  
date: 2025-06-04  
categories:  
  - Lecture Notes  
  - Computer Architecture  
---  
## Flynn’s Taxonomy  
  
||Single Inst.|Multiple Inst.|  
|---|---|---|  
|Single Data|SISD: Vanilla Processor.||  
  
Single processor work on single data with single instruction | MISD: Multiple instruction stream for single data stream.  
  
ex. CPU가 잘 작동하는지 reliability 테스트 | | Multiple Data | SIMD: Multiple PEs controlled by a common instruction. Working on data independently.  
  
ex. GPU | MIMD: fully-independent programs. control flows working in parallel  
  
ex. Multiple CPUs (multicore) |  
  
---  
  
## Data Parallelism  
  
어떤 명령어는 vector processing을 지원한다.  
  
하나의 명령어를 가지고 여러개의 데이터를 처리하는 방식. (= Vector processing)  
  
폰 노이만 구조에서는 모든 명령어가 메모리에 있어서 매번 명령어를 메모리에서 n번 가져와야함. (instruction fetch bottleneck)근데 데이터만 다르고 똑같은 명령어니까 그냥 병렬적으로 처리하자. 그리고 벡터 계산 명령어를 정의해서 주자!  
  
---  
  
## AMD  
  
### What about branching?  
  
- ALU 1 ~ ALU 8이 각 벡터의 원소를 실행.  
- 분기 발생 시 각 벡터 원소 별 T, F 판단.  
- taken인 명령어만 남겨놓고 해당 명령어들을 쭉 실행. 아닌 원소들은 X표시.  
- 그 후 not taken 경로로 가면 나머지 원소들을 실행. 원래껀 X  
- Not All ALUs do useful works. 1/8 performance can occur  
  
### Hmm… no prediction and stall?  
  
그렇다. 분기 여부를 어차피 warp단위로 하니 할 필요도 없다. 마스크 변경이나 분기로 인한 오버헤드가 심해 stall이 걸리면, 스케줄러는 그냥 그 warp 빼버리고 다른 벡터를 실행한다.  
  
또는, 해보니까 X가 너무 많이 느릴 것 같으면 빼버릴 수 있다.  
  
→ memory latency가 숨겨질 수 있다. (왜? 우리는 개별 코어를 많이 만들어놨고, set도 4배 정도 있기 때문에 빼고 해당 코어에서 다른거 실행해도 된다.